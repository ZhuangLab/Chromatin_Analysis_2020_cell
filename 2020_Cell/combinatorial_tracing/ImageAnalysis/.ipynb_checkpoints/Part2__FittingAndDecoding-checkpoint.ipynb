{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Author:__ Bogdan Bintu\n",
    "\n",
    "__Email:__ bbintu@g.harvard.edu\n",
    "\n",
    "__Date:__ 3/4/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment DAPI images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,cv2,os,glob\n",
    "import tifffile\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import scipy.ndimage as ndi\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import watershed\n",
    "from skimage.segmentation import random_walker\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### usefull functions\n",
    "def get_frame(dax_fl,ind_z=1,sx=2048,sy=2048):\n",
    "    \"returns single frame of a dax file at frame ind_z\"\n",
    "    f = open(dax_fl, \"rb\")\n",
    "    bytes_frame = sx*sy*2\n",
    "    f.seek(bytes_frame*ind_z)\n",
    "    im_ = np.fromfile(f,dtype=np.uint16,count=sx*sy).reshape([sx,sy]).swapaxes(0,1)\n",
    "    f.close()\n",
    "    return im_\n",
    "def im2d_to_infocus(im_,bs = 11,mbs=7,th_b = 1.6,th_s = 0.15,plt_val=False):\n",
    "    \"\"\"Takes a 2d image and thresholds it based on the level of the signal and the local standard deviation of the sinal\n",
    "    This is used to threshold image prior to cell segmentation.\n",
    "    \"\"\"\n",
    "    im_sq_blur = cv2.blur(im_*im_,(bs,bs))\n",
    "    im_blur_sq = cv2.blur(im_,(bs,bs))\n",
    "    im_blur_sq *=im_blur_sq\n",
    "    im_std = np.sqrt(im_sq_blur - im_blur_sq)\n",
    "    \n",
    "    im__ = (im_std<th_s)&(im_<th_b)\n",
    "    im_in = np.array(1-im__,dtype=np.uint8)\n",
    "    im_in = cv2.medianBlur(im_in,mbs)\n",
    "    \n",
    "    if plt_val:\n",
    "        plt.figure()\n",
    "        plt.plot(im_std.ravel(),im_.ravel(),'o',alpha=0.01)\n",
    "        plt.show()\n",
    "        plt.figure(figsize=(15,15))\n",
    "        plt.imshow(im_,cmap='gray')\n",
    "        plt.contour(im_in,[0.5],colors=['r'])\n",
    "        plt.show()\n",
    "    return im_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_folder=r'\\\\10.245.74.218\\Raw_data\\Bogdan\\7_27_2019_IMR90RNA'\n",
    "analysis_folder = master_folder+'-Analysis'\n",
    "analysis_folder = analysis_folder+os.sep+'_CellSegm_Analysis'\n",
    "if not os.path.exists(analysis_folder):\n",
    "    os.makedirs(analysis_folder)\n",
    "H0_folder = glob.glob(master_folder+os.sep+'H*B,B')[0]\n",
    "dax_files = glob.glob(H0_folder+os.sep+'*.dax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check a frame of a field of view of the nuclear signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dapi_mean = np.load(analysis_folder+os.sep+'dapi_mean.npy')\n",
    "dax_file = dax_files[60]\n",
    "im = get_frame(dax_file,ind_z=5*45-1)\n",
    "\n",
    "im=im/dapi_mean\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(im,vmax=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check paramaters for initial thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_in = im2d_to_infocus(im[::2,::2],bs = 10,mbs=7,th_b = 3.5,th_s = 0.4,plt_val=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core functions for cell segmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_uint8(im,min_=None,max_=None):\n",
    "    im_ = np.array(im,dtype=np.float32)\n",
    "    if min_ is None: min_ = np.min(im)\n",
    "    if max_ is None: max_ = np.max(im)\n",
    "    delta = max_-min_\n",
    "    if delta==0: delta =1\n",
    "    im_ = (im-min_)/delta\n",
    "    im_ = (np.clip(im_,0,1)*255).astype(np.uint8)\n",
    "    return im_\n",
    "def save_3dSegmentation_tif(im_base,imcells3d,imcells3d_lims,save_file,min_=0,max_=2):\n",
    "    im_overlay = cast_uint8(im_base,min_=min_,max_=max_)\n",
    "    im_overlay = np.array([im_overlay,im_overlay,im_overlay]).swapaxes(0,-1).swapaxes(0,1).swapaxes(1,2)\n",
    "\n",
    "    for index in range(len(imcells3d_lims)):\n",
    "        zm,zM,xm,xM,ym,yM = imcells3d_lims[index]\n",
    "        imcells3d_red =  imcells3d[zm:zM,xm:xM,ym:yM]==index+1\n",
    "        for zmed in range(zM-zm):\n",
    "            if zmed<len(imcells3d_red):\n",
    "                im_2d = imcells3d_red[zmed]\n",
    "                cont_results = cv2.findContours(im_2d.astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                contour = cont_results[0]#np.squeeze()\n",
    "                #print contour,cont_results\n",
    "                if len(contour)>0:\n",
    "                    base_im = np.zeros([xM-xm,yM-ym,3],dtype = np.uint8)\n",
    "                    cont_im = cv2.polylines(base_im, contour,1, (128,0,0),2)\n",
    "                    xs,ys = np.where(im_2d)\n",
    "                    cm = (int(np.mean(ys)),int(np.mean(xs)))\n",
    "                    cv2.putText(cont_im,str(index+1),cm, \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX,0.33,(0,255,255),1,cv2.LINE_AA)\n",
    "                    im_overlay_ = im_overlay[zm+zmed,xm:xM,ym:yM]\n",
    "\n",
    "                    im_overlay[zm+zmed,xm:xM,ym:yM] = np.clip(im_overlay_+cont_im*1.,0,255).astype(np.uint8)\n",
    "    tifffile.imwrite(save_file,im_overlay,compress=0)\n",
    "\n",
    "def segment_daxfl(dax_file,save_file):\n",
    "    print(\"Loading:\",dax_file)\n",
    "    im = get_frame(dax_file,ind_z=5*45-1)\n",
    "    im=im/dapi_mean\n",
    "    im_mask_2d = im2d_to_infocus(im[::2,::2],bs = 10,mbs=7,th_b = 3.5,th_s = 0.4,plt_val=False)\n",
    "    #im_mask = np.swapaxes(im_mask,0,1)\n",
    "    #im_mask = np.array([cv2.medianBlur(im_,11) for im_ in im_mask ])\n",
    "    #im_mask_2d = np.max(im_mask,0)>0\n",
    "    im_mask_2d = ndi.binary_fill_holes(im_mask_2d>0)\n",
    "    dist = ndi.distance_transform_edt(im_mask_2d) #distance transformation for watershed\n",
    "    local_max = peak_local_max(dist, indices = False, min_distance=20)\n",
    "    x,y = np.where(local_max)\n",
    "    X=np.array([x,y]).T\n",
    "    distM = cdist(X,X)\n",
    "    distM[range(len(X)),range(len(X))]=np.inf\n",
    "    xp,yp = np.where(distM<30)\n",
    "    ik=np.setdiff1d(np.arange(len(x)),xp[xp>yp])\n",
    "    x,y = x[ik],y[ik]\n",
    "    local_max = 0*im_mask_2d\n",
    "    local_max[np.array(x,dtype=int),np.array(y,dtype=int)]=1\n",
    "    markers = ndi.label(local_max)[0]\n",
    "    markers[im_mask_2d==0] = -1\n",
    "    labeled_dapi = random_walker(im_mask_2d, markers)\n",
    "    labeled_dapi[labeled_dapi==-1]=0\n",
    "\n",
    "    im_temp = np.array(labeled_dapi)\n",
    "    xs,ys = np.where(im_temp>0)\n",
    "    delta = 1\n",
    "    bad = (xs<delta)|(xs>=im_temp.shape[0]-delta)|(ys<delta)|(ys>=im_temp.shape[1]-delta)\n",
    "    bad_inds = np.unique(im_temp[xs[bad],ys[bad]])\n",
    "    for ind in bad_inds:\n",
    "        im_temp[im_temp==ind]=0\n",
    "\n",
    "    #labeled_nuc, num_nuc = ndi.label(im)\n",
    "    inds = np.unique(im_temp)[1:]\n",
    "    im_ = np.array(im_temp)\n",
    "    ct = 0\n",
    "    for iind,ind in enumerate(inds):\n",
    "        kp = im_==ind\n",
    "        area = np.sum(kp)\n",
    "        if area>2000:\n",
    "            ct+=1\n",
    "            im_temp[kp]=ct\n",
    "        else:\n",
    "            im_temp[kp]=0\n",
    "    im = np.array([im])\n",
    "    imcells3d = np.array([im_temp]*len(im),dtype=np.uint16)\n",
    "    \n",
    "    np.save(save_file,imcells3d)\n",
    "    \n",
    "    imcells3d_lims = []\n",
    "    pad = 20\n",
    "    for celli in np.unique(im_temp)[1:]:\n",
    "        x,y = np.where(im_temp==celli)\n",
    "        xm,xM,ym,yM = np.min(x)-pad,np.max(x)+pad,np.min(y)-pad,np.max(y)+pad\n",
    "        zm,zM = 0,len(im)\n",
    "        if xM>im_temp.shape[0]:xM=im_temp.shape[0]-1\n",
    "        if yM>im_temp.shape[1]:yM=im_temp.shape[1]-1\n",
    "        if xm<0:xm=0\n",
    "        if ym<0:ym=0\n",
    "        imcells3d_lims.append([zm,zM,xm,xM,ym,yM])\n",
    "    imcells3d_lims = np.array(imcells3d_lims)\n",
    "    np.save(save_file.replace('__imcells2d.npy','__imcells2d_lims.npy'),imcells3d_lims)\n",
    "    save_3dSegmentation_tif(im[:,::2,::2],imcells3d,imcells3d_lims,save_file.replace('__imcells2d.npy','__2dshow.tif'),\n",
    "                           min_=0,max_=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run cell segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dax_files = np.sort(dax_files)\n",
    "for dax_file in tqdm(dax_files[:]):\n",
    "    save_file  = analysis_folder+os.sep+os.path.basename(dax_file).replace('.dax','__imcells2d.npy')\n",
    "    segment_daxfl(dax_file,save_file)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform manual correction to automatic cell segmentaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,glob,sys\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import scipy.ndimage as ndi\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import cv2\n",
    "import IOTools as io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make and write a png file with the automatic mask in one channel and the DAPI signal in another by concatenating across all fields of view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d50e1a08b61345f1905f5e918a780044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=70), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dapiSeg = r'masterAnalysisFolder\\_CellSegm_Analysis'\n",
    "seg_fls = np.sort(glob.glob(dapiSeg+os.sep+'*__imcells2d.npy'))\n",
    "dapiFolder = r'dapi_folder'\n",
    "\n",
    "im_comps = []\n",
    "for seg_fl in tqdm(seg_fls):\n",
    "    dapi_fl = dapiFolder+os.sep+os.path.basename(seg_fl).replace('__imcells2d.npy','.dax')\n",
    "    im_mask = np.load(seg_fl)[0].T\n",
    "    nmax = np.max(im_mask)+1\n",
    "    im_edge = np.zeros_like(im_mask)\n",
    "    for iobj in range(1,nmax):\n",
    "        im_mask_ = (im_mask==iobj).astype(np.uint8)\n",
    "        kernel = np.ones([3,3],dtype=np.uint8)#cv2.getStructuringElement(cv2.MORPH_OPEN,(4,4))\n",
    "        im_erode = cv2.erode(im_mask_,kernel)\n",
    "        im_edge += im_mask_-im_erode\n",
    "    imf = (1-(im_edge>0))*(im_mask>0)\n",
    "    im = np.array(io.DaxReader(dapi_fl).loadMap()[5*45-1][::2,::2],dtype=np.float32)\n",
    "    im_dapi = im/np.max(im)\n",
    "    im_comp = np.dstack([imf*0,im_dapi,imf*0.5])\n",
    "    im_comps.append(im_comp)\n",
    "    \n",
    "    #plt.figure()\n",
    "    #plt.imshow(im_comp)\n",
    "    #plt.show()\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(r'masterAnalysisFolder\\_CellSegm_Analysis\\all_masks.png',\n",
    "            (np.concatenate(im_comps,axis=0)*255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refine the _allmask_ file in Photoshop to correct missegmentation and then load it in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(r'masterAnalysisFolder\\_CellSegm_Analysis\\all_masks.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restructure refined mask and save for each field of view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0a151cd5304909838abc63e5007546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=70), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "im_mask = im[:,:,-1].reshape([-1,1024,1024])\n",
    "nlabtot=0\n",
    "dapi_fls = np.sort(glob.glob(r'dapi_folder\\*.dax'))\n",
    "save_folder = r'masterAnalysisFolder\\_CellSegm_Analysis\\cnn_segmentation'\n",
    "if not os.path.exists(save_folder):os.makedirs(save_folder)\n",
    "for im_m,dax_file in tqdm(zip(im_mask,dapi_fls)):\n",
    "    #print(\"Loading:\",dax_file)\n",
    "    save_file  = save_folder+os.sep+os.path.basename(dax_file).replace('.dax','__imcells3d.npy')\n",
    "    im_dapi = io.DaxReader(dax_file).loadMap()\n",
    "    im_dapi = im_dapi[:-10][4::5][2:]\n",
    "    nz = len(im_dapi)\n",
    "    im_dapi = np.array(im_dapi[int(nz/2)])\n",
    "    \n",
    "    im_ = np.array(im_m>100,dtype=np.uint8)\n",
    "    nlab,imlab,res,centers = cv2.connectedComponentsWithStats(im_)\n",
    "    im_temp = imlab.copy()\n",
    "    inds = np.unique(im_temp)[1:]\n",
    "    im_ = np.array(im_temp)\n",
    "    ct = 0\n",
    "    for iind,ind in enumerate(inds):\n",
    "        kp = im_==ind\n",
    "        area = np.sum(kp)\n",
    "        if area>100:\n",
    "            ct+=1\n",
    "            im_temp[kp]=ct\n",
    "        else:\n",
    "            im_temp[kp]=0\n",
    "    imlab = im_temp\n",
    "    \n",
    "    imcells3d = np.array([imlab]*nz,dtype=np.uint16)\n",
    "    np.save(save_file,imcells3d)\n",
    "    imcells3d_lims = []\n",
    "    pad = 20\n",
    "    \n",
    "    for celli in np.unique(imlab)[1:]:\n",
    "        x,y = np.where(imlab==celli)\n",
    "        xm,xM,ym,yM = np.min(x)-pad,np.max(x)+pad,np.min(y)-pad,np.max(y)+pad\n",
    "        zm,zM = 0,len(im)-1\n",
    "        if xM>imlab.shape[0]:xM=imlab.shape[0]-1\n",
    "        if yM>imlab.shape[1]:yM=imlab.shape[1]-1\n",
    "        if xm<0:xm=0\n",
    "        if ym<0:ym=0\n",
    "        imcells3d_lims.append([zm,zM,xm,xM,ym,yM])\n",
    "    imcells3d_lims = np.array(imcells3d_lims)\n",
    "    np.save(save_file.replace('__imcells3d.npy','__imcells3d_lims.npy'),imcells3d_lims)\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plt.contour(im_,[0.5],colors=['r'])\n",
    "    plt.imshow(im_dapi[::2,::2])\n",
    "    fig.savefig(save_file.replace('.npy','.png'))\n",
    "    plt.close()\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the signal per each cell per each filed of view. Also use the bead data to align."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn on clusters\n",
    "#Open terminal and run: ipcluster start -n 20\n",
    "import ipyparallel as ipp\n",
    "from ipyparallel import Client\n",
    "rc = Client()\n",
    "def f(index):\n",
    "    import sys\n",
    "    sys.path.append(r'path_to_current_code')\n",
    "    import workers_cells_v2 as wkc\n",
    "    reload(wkc)\n",
    "    try:\n",
    "        obj = wkc.cell_focus(index_fov=index,dataset_tag='tag_condition',\n",
    "                   parent_dapiSeg=r'masterAnalysisFolder\\_CellSegm_Analysis',\n",
    "                  parent_fits_analysis=r'masterAnalysisFolder',\n",
    "                  parent_save = r'saveFolder',\n",
    "                  fl_750_647 = r'ChromaticAberation\\dic_chr_150nm_IMR90_v2.pkl',#\n",
    "                  fl_750_561 = r'ChromaticAberation\\dic_chr_150nm_IMR90_v2.pkl',#\n",
    "                  RNA_dapi_tag = 'dapitag',\n",
    "                  overwrite=False)\n",
    "    \n",
    "        if not obj.is_complete():\n",
    "            obj.z_cutoff=5\n",
    "            obj.pad=10\n",
    "            obj.master_folder=r'master_data_folder'\n",
    "            obj.apply_to_pfits()\n",
    "            obj.save()\n",
    "        success = True\n",
    "    except:\n",
    "        success = False\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = rc[:].map_sync(f,range(70)) #70 indicates the number of field of views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load all the fitted data per cell across all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob,os,sys\n",
    "import numpy as np\n",
    "import workers_cells_v3 as wkc\n",
    "import PostFitting as pf\n",
    "reload(pf)\n",
    "reload(wkc)\n",
    "files = np.sort(glob.glob(r'saveFolder\\cell_dics\\*_cells.npy'))\n",
    "cell_obj = wkc.cell_analysis(files[:])#,5,6,7,8\n",
    "cell_obj.normalize_cell_dic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check drift errors acros field of views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check drift errors\n",
    "fovs = np.sort(cell_obj.dic_noncells.keys())\n",
    "for fov in fovs:\n",
    "    cell_obj.dic_noncell = cell_obj.dic_noncells[fov]\n",
    "    errors,drifts = [],[]\n",
    "    for i in range(100):\n",
    "        errors.append(cell_obj.dic_noncell['drift_errors']['R'+str(i+1)])\n",
    "        drifts.append(cell_obj.dic_noncell['dic_drift_final']['R'+str(i+1)][0][:,0])\n",
    "    errors,drifts =np.array(errors),np.array(drifts)\n",
    "    plt.figure()\n",
    "    plt.title(fov+'-Drift-error')\n",
    "    plt.plot(errors[:,0])\n",
    "    plt.plot(errors[:,1])\n",
    "    plt.plot(errors[:,2])\n",
    "    plt.ylim([0,1])\n",
    "    plt.figure()\n",
    "    plt.title(fov+'-Drift')\n",
    "    plt.plot(drifts[:,0])\n",
    "    plt.plot(drifts[:,1])\n",
    "    plt.plot(drifts[:,2])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test decoding per one cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(wkc)\n",
    "\n",
    "###Load a cell from the dataset i.e. cell 95\n",
    "cell_obj.set_cell(95)\n",
    "print cell_obj.cell\n",
    "\n",
    "#decide whether to apply a different chromatic abberation correction\n",
    "if False:\n",
    "    fl = r'ChromaticAberation\\dic_chr_150nm_IMR90_v2.pkl'\n",
    "    dic_chr = np.load(fl)\n",
    "    ms_chr = [None,dic_chr['m_750_647'],dic_chr['m_750_561']]\n",
    "    cell_obj = wkc.update_color(cell_obj,ms_chr)\n",
    "\n",
    "########## DNA ####################\n",
    "#load the DNA code\n",
    "cell_obj.load_DNA_code()\n",
    "#get a list of candidates that are roughly in the correct ~200nm threshold\n",
    "cell_obj.get_candidates(cutoff_candidate = [2.25,1.75,1.75],cap_invalid = 4000)\n",
    "cell_obj.get_main_scores()\n",
    "cell_obj.get_th_bleed(nkeep=2,plt_val=False)\n",
    "cell_obj.get_chr_points()\n",
    "\n",
    "cell_obj.get_chr_trees()\n",
    "cell_obj.enhance_scores_1(nneigh=15)\n",
    "cell_obj.get_th_bleed(nkeep=2,plt_val=False)\n",
    "cell_obj.get_chr_points()\n",
    "print cell_obj.bleed_score,cell_obj.coverage\n",
    "\n",
    "#separate into homologs\n",
    "#cell_obj.get_homolog_centers_single(ichr_ = 1,plt_val=True)\n",
    "cell_obj.get_homolog_centers()\n",
    "cell_obj.enhance_scores_2(ihom=0)\n",
    "cell_obj.Distrib1,cell_obj.DsCC1 = cell_obj.DsCC_distr_valid[:],cell_obj.DsCC_valid\n",
    "cell_obj.get_th_bleed(nkeep=1,plt_val=False)\n",
    "cell_obj.th_score1,cell_obj.scores_valid1 = cell_obj.th_score,cell_obj.scores_valid[:]\n",
    "cell_obj.enhance_scores_2(ihom=1,Distrib=cell_obj.Distrib1)\n",
    "cell_obj.Distrib2,cell_obj.DsCC2 = cell_obj.DsCC_distr_valid[:],cell_obj.DsCC_valid\n",
    "cell_obj.get_th_bleed(nkeep=1,plt_val=False)\n",
    "cell_obj.th_score2,cell_obj.scores_valid2 = cell_obj.th_score,cell_obj.scores_valid[:]\n",
    "cell_obj.get_chr_points_homologs()\n",
    "\n",
    "def compare(pts1,pts2,nan=True):\n",
    "    good_num,all_num = 0,0\n",
    "    for pts1_chr,pts2_chr in zip(pts1,pts2):\n",
    "        pts1_chr,pts2_chr=np.array(pts1_chr),np.array(pts2_chr)\n",
    "        if nan:\n",
    "            pts1_chr[np.isnan(pts1_chr)]=np.inf\n",
    "            pts2_chr[np.isnan(pts2_chr)]=np.inf\n",
    "        good_num+=np.sum(np.all(pts1_chr==pts2_chr,axis=-1))\n",
    "        all_num+=len(pts1_chr)\n",
    "    return good_num/float(all_num)\n",
    "print compare(cell_obj.points1+cell_obj.points2,cell_obj.points1+cell_obj.points2,nan=False)\n",
    "for irep in range(2):\n",
    "    cell_obj.enhance_scores_2(ihom=0,Distrib=cell_obj.refined_Distr)\n",
    "    cell_obj.Distrib1,cell_obj.DsCC1 = cell_obj.DsCC_distr_valid[:],cell_obj.DsCC_valid\n",
    "    cell_obj.get_th_bleed(nkeep=1,plt_val=False)\n",
    "    cell_obj.th_score1,cell_obj.scores_valid1 = cell_obj.th_score,cell_obj.scores_valid[:]\n",
    "    cell_obj.enhance_scores_2(ihom=1,Distrib=cell_obj.refined_Distr)\n",
    "    cell_obj.Distrib2,cell_obj.DsCC2 = cell_obj.DsCC_distr_valid[:],cell_obj.DsCC_valid\n",
    "    cell_obj.get_th_bleed(nkeep=1,plt_val=False)\n",
    "    cell_obj.th_score2,cell_obj.scores_valid2 = cell_obj.th_score,cell_obj.scores_valid[:]\n",
    "    cell_obj.points1_prev,cell_obj.points2_prev = cell_obj.points1,cell_obj.points2\n",
    "    cell_obj.get_chr_points_homologs()\n",
    "    print compare(cell_obj.points1_prev,cell_obj.points1),compare(cell_obj.points2_prev,cell_obj.points2)\n",
    "    print compare(cell_obj.points1+cell_obj.points2,cell_obj.points1+cell_obj.points2,nan=False)\n",
    "#plot a few positions\n",
    "for chri in [0,1,2,3,5,20,21]:\n",
    "    fig = cell_obj.plot_chr(chri=chri,ax1=1,ax2=2)\n",
    "    #fig.savefig(save_base+'__chri'+str(chri)+'.png')\n",
    "cell_obj.plot_cell_chromatic_difference(col_check = [1,0])\n",
    "cell_obj.plot_cell_chromatic_difference(col_check = [0,1])\n",
    "\n",
    "########## RNA ####################\n",
    "cell_obj.clean_Qs(h_cutoff=4.,zxy_cutoff=1.5)\n",
    "for key in cell_obj.dic_cell:\n",
    "    if 'Q' in key:\n",
    "        cell_obj.dic_cell[key] = cell_obj.dic_cell[key][:50]\n",
    "cell_obj.load_RNA_code()\n",
    "cell_obj.get_candidates(cutoff_candidate = [2.25,1.75,1.75],cap_invalid = 4000)\n",
    "#rough RNA\n",
    "dna_zxy,rna_zxy,ps_rna,dna_loc,rna_names,rna_iqs,fig = cell_obj.get_dna_rna_pts(drift=[0,0,0],cutoff_dist=15,plt_val=False)\n",
    "#print(len(rna_zxy))\n",
    "#fine RNA\n",
    "drift = np.nanmedian(rna_zxy-dna_zxy,axis=0)\n",
    "dna_zxy,rna_zxy,ps_rna,dna_loc,rna_names,rna_iqs,fig = cell_obj.get_dna_rna_pts(drift=drift,cutoff_dist=10.,plt_val=True)\n",
    "print(\"Number of RNA:\",len(rna_zxy))\n",
    "#cell_obj.get_main_scores()\n",
    "#cell_obj.get_th_bleed(nkeep=1,plt_val=True)\n",
    "ps_pairs_final = [[[cell_obj.ps_pairs_valid_keep1[iv],cell_obj.ps_pairs_valid_keep2[iv]]\n",
    "                   for iv in ichrs]\n",
    "                  for ichrs in cell_obj.chr_ivs]\n",
    "dic_save = {'dna_ps_pairs':ps_pairs_final,'dna_zxy':[cell_obj.points1,cell_obj.points2]}\n",
    "dic_save.update({'dna_fromRNA_zxy':dna_zxy,'rna_zxy':rna_zxy,\n",
    "                 'ps_rna':ps_rna,'dna_fromRNA_loc':dna_loc,'rna_names':rna_names,\n",
    "                'rna_dna_drift':drift,'cell':cell_obj.cell,'dna_refined_Distr':cell_obj.refined_Distr})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run across all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_cells(list_cells=None):\n",
    "    import glob,os,sys\n",
    "    import numpy as np\n",
    "    sys.path.append(r'analysis_code_path')\n",
    "    import workers_cells_v2 as wkc\n",
    "    import PostFitting as pf\n",
    "    reload(pf)\n",
    "    reload(wkc)\n",
    "    from tqdm import tqdm_notebook as tqdm\n",
    "    import matplotlib.pylab as plt\n",
    "    import cPickle as pickle\n",
    "    success=True\n",
    "    #Load all the data\n",
    "    files = np.sort(glob.glob(r'analysis_save_folder\\cell_dics\\*_cells.npy'))\n",
    "    cell_obj = wkc.cell_analysis(files[:])#,5,6,7,8\n",
    "    cell_obj.normalize_cell_dic()\n",
    "    \n",
    "\n",
    "    master_folder = os.path.dirname(os.path.dirname(files[0]))\n",
    "    save_folder = master_folder+os.sep+'cell_decoding'\n",
    "    save_folder = r'new_save_folder'+os.sep+os.path.basename(master_folder)+os.sep+'cell_decoding_refitted2'\n",
    "    print save_folder\n",
    "    if not os.path.exists(save_folder): os.makedirs(save_folder)\n",
    "    overwrite = False\n",
    "    if list_cells is None: list_cells = range(len(cell_obj.cells))\n",
    "    \n",
    "    #remap chromatic abberation\n",
    "    fl = r'ChromaticAberation\\dic_chr_150nm_IMR90_v2.pkl'\n",
    "    dic_chr = np.load(fl)\n",
    "    ms_chr = [None,dic_chr['m_750_647'],dic_chr['m_750_561']]\n",
    "\n",
    "    for icell in tqdm(list_cells):\n",
    "        \n",
    "        try:\n",
    "        #if True:\n",
    "            cell_obj.set_cell(icell)\n",
    "            \n",
    "            save_base = save_folder+os.sep+cell_obj.cell\n",
    "            print save_base\n",
    "            \n",
    "            if overwrite or not os.path.exists(save_base+'.pkl'):\n",
    "            #if True:\n",
    "                fid=open(save_base+'.new','w')\n",
    "                fid.close()\n",
    "                cell_obj = wkc.update_color(cell_obj,ms_chr)\n",
    "                cell_obj.load_DNA_code()\n",
    "                cell_obj.get_candidates(cutoff_candidate = [2.25,1.75,1.75],cap_invalid = 4000)\n",
    "                cell_obj.get_main_scores()\n",
    "                cell_obj.get_th_bleed(nkeep=2,plt_val=False)\n",
    "                cell_obj.get_chr_points()\n",
    "\n",
    "                cell_obj.get_chr_trees()\n",
    "                cell_obj.enhance_scores_1(nneigh=15)\n",
    "                cell_obj.get_th_bleed(nkeep=2,plt_val=False)\n",
    "                cell_obj.get_chr_points()\n",
    "                print cell_obj.bleed_score,cell_obj.coverage\n",
    "\n",
    "                #separate into homologs\n",
    "                #cell_obj.get_homolog_centers_single(ichr_ = 1,plt_val=True)\n",
    "                cell_obj.get_homolog_centers()\n",
    "                cell_obj.enhance_scores_2(ihom=0)\n",
    "                cell_obj.Distrib1,cell_obj.DsCC1 = cell_obj.DsCC_distr_valid[:],cell_obj.DsCC_valid\n",
    "                cell_obj.get_th_bleed(nkeep=1,plt_val=False)\n",
    "                cell_obj.th_score1,cell_obj.scores_valid1 = cell_obj.th_score,cell_obj.scores_valid[:]\n",
    "                cell_obj.enhance_scores_2(ihom=1,Distrib=cell_obj.Distrib1)\n",
    "                cell_obj.Distrib2,cell_obj.DsCC2 = cell_obj.DsCC_distr_valid[:],cell_obj.DsCC_valid\n",
    "                cell_obj.get_th_bleed(nkeep=1,plt_val=False)\n",
    "                cell_obj.th_score2,cell_obj.scores_valid2 = cell_obj.th_score,cell_obj.scores_valid[:]\n",
    "                cell_obj.get_chr_points_homologs()\n",
    "\n",
    "                def compare(pts1,pts2,nan=True):\n",
    "                    good_num,all_num = 0,0\n",
    "                    for pts1_chr,pts2_chr in zip(pts1,pts2):\n",
    "                        pts1_chr,pts2_chr=np.array(pts1_chr),np.array(pts2_chr)\n",
    "                        if nan:\n",
    "                            pts1_chr[np.isnan(pts1_chr)]=np.inf\n",
    "                            pts2_chr[np.isnan(pts2_chr)]=np.inf\n",
    "                        good_num+=np.sum(np.all(pts1_chr==pts2_chr,axis=-1))\n",
    "                        all_num+=len(pts1_chr)\n",
    "                    return good_num/float(all_num)\n",
    "                print compare(cell_obj.points1+cell_obj.points2,cell_obj.points1+cell_obj.points2,nan=False)\n",
    "                for irep in range(2):\n",
    "                    cell_obj.enhance_scores_2(ihom=0,Distrib=cell_obj.refined_Distr)\n",
    "                    cell_obj.Distrib1,cell_obj.DsCC1 = cell_obj.DsCC_distr_valid[:],cell_obj.DsCC_valid\n",
    "                    cell_obj.get_th_bleed(nkeep=1,plt_val=False)\n",
    "                    cell_obj.th_score1,cell_obj.scores_valid1 = cell_obj.th_score,cell_obj.scores_valid[:]\n",
    "                    cell_obj.enhance_scores_2(ihom=1,Distrib=cell_obj.refined_Distr)\n",
    "                    cell_obj.Distrib2,cell_obj.DsCC2 = cell_obj.DsCC_distr_valid[:],cell_obj.DsCC_valid\n",
    "                    cell_obj.get_th_bleed(nkeep=1,plt_val=False)\n",
    "                    cell_obj.th_score2,cell_obj.scores_valid2 = cell_obj.th_score,cell_obj.scores_valid[:]\n",
    "                    cell_obj.points1_prev,cell_obj.points2_prev = cell_obj.points1,cell_obj.points2\n",
    "                    cell_obj.get_chr_points_homologs()\n",
    "                    print compare(cell_obj.points1_prev,cell_obj.points1),compare(cell_obj.points2_prev,cell_obj.points2)\n",
    "                    print compare(cell_obj.points1+cell_obj.points2,cell_obj.points1+cell_obj.points2,nan=False)\n",
    "                #plot a few positions\n",
    "                for chri in [0,1,2,3,5,20,21]:\n",
    "                    fig = cell_obj.plot_chr(chri=chri,ax1=1,ax2=2)\n",
    "                    fig.savefig(save_base+'__chri'+str(chri)+'.png')\n",
    "                cell_obj.plot_cell_chromatic_difference(col_check = [1,0])\n",
    "                cell_obj.plot_cell_chromatic_difference(col_check = [0,1])\n",
    "\n",
    "                ########## RNA ####################\n",
    "                cell_obj.clean_Qs(ih=-7,h_cutoff=4.,zxy_cutoff=1.5)\n",
    "                for key in cell_obj.dic_cell:\n",
    "                    if 'Q' in key:\n",
    "                        cell_obj.dic_cell[key] = cell_obj.dic_cell[key][:50]\n",
    "                cell_obj.load_RNA_code()\n",
    "                cell_obj.get_candidates(cutoff_candidate = [1.75,1.75,1.75],cap_invalid = 4000)\n",
    "                #rough RNA\n",
    "                dna_zxy,rna_zxy,ps_rna,dna_loc,rna_names,rna_iqs,fig = cell_obj.get_dna_rna_pts(drift=[0,0,0],cutoff_dist=15,plt_val=False)\n",
    "                #print(len(rna_zxy))\n",
    "                #fine RNA\n",
    "                drift = np.nanmedian(rna_zxy-dna_zxy,axis=0)\n",
    "                dna_zxy,rna_zxy,ps_rna,dna_loc,rna_names,rna_iqs,fig = cell_obj.get_dna_rna_pts(drift=drift,cutoff_dist=10.,plt_val=True)\n",
    "                fig.savefig(save_base+'_RNA.png')\n",
    "                print(\"Number of RNA:\",len(rna_zxy))\n",
    "                #cell_obj.get_main_scores()\n",
    "                #cell_obj.get_th_bleed(nkeep=1,plt_val=True)\n",
    "                ps_pairs_final = [[[cell_obj.ps_pairs_valid_keep1[iv],cell_obj.ps_pairs_valid_keep2[iv]]\n",
    "                                   for iv in ichrs]\n",
    "                                  for ichrs in cell_obj.chr_ivs]\n",
    "                dic_save = {'dna_ps_pairs':ps_pairs_final,'dna_zxy':[cell_obj.points1,cell_obj.points2]}\n",
    "                dic_save.update({'dna_fromRNA_zxy':dna_zxy,'rna_zxy':rna_zxy,\n",
    "                                 'ps_rna':ps_rna,'dna_fromRNA_loc':dna_loc,'rna_names':rna_names,\n",
    "                                'rna_dna_drift':drift,'cell':cell_obj.cell,'dna_refined_Distr':cell_obj.refined_Distr})\n",
    "                plt.close('all')\n",
    "                pickle.dump(dic_save,open(save_base+'.pkl','wb'))\n",
    "            \n",
    "        except:\n",
    "            print(\"Failed \",getattr(cell_obj,'cell','None'))\n",
    "            success=False\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn on clusters\n",
    "#Open terminal and run: ipcluster start -n 20\n",
    "import ipyparallel as ipp\n",
    "from ipyparallel import Client\n",
    "rc = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrc = len(rc)\n",
    "paramaters = range(2000)\n",
    "paramaters=[paramaters[icl::nrc] for icl in range(nrc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = rc[:].map_sync(analyze_cells,paramaters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chromatic aberation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_im(dax_fl,icols=[0],num_cols=3,sx=2048,sy=2048):\n",
    "    im = np.fromfile(dax_fl,dtype=np.uint16).reshape([-1,sx,sy]).swapaxes(1,2)\n",
    "    return [im[icol::num_cols] for icol in icols]\n",
    "def normalzie_im(im,sz=10):\n",
    "    im_ = np.array(im,dtype=np.float32)\n",
    "    im_blur = np.array([cv2.blur(im__,(sz,sz)) for im__ in im_])\n",
    "    im_ =im_/(im_blur)\n",
    "    return im_\n",
    "def get_standard_fits(im,th_stds = 6,sz_blur=10,better_fit=False):\n",
    "    im_norm = normalzie_im(im,sz_blur)\n",
    "    hcutoff = 1+np.std(im_norm-1)*th_stds\n",
    "    #hcutoff=1.5\n",
    "    z,x,y = np.where(im_norm>hcutoff)\n",
    "    h_im = im_norm[z,x,y]\n",
    "    sz,sx,sy = im_norm.shape\n",
    "    keep = h_im>0\n",
    "    deltas = range(-3,4)\n",
    "    for deltax in deltas:\n",
    "        for deltay in deltas:\n",
    "            for deltaz in deltas:\n",
    "                    keep &= (h_im>=im_norm[(z+deltaz)%sz,(x+deltax)%sx,(y+deltay)%sy])\n",
    "    zf,xf,yf = z[keep],x[keep],y[keep]\n",
    "    hf = im_norm[zf,xf,yf]\n",
    "    centers_zxy = np.array([zf,xf,yf]).T\n",
    "    pfits = ft.fast_fit_big_image(im.astype(np.float32),centers_zxy,radius_fit = 4,avoid_neigbors=True,\n",
    "                          recenter=False,verbose = False,better_fit=better_fit,troubleshoot=False)\n",
    "    return pfits\n",
    "def sort_pfits(pfits):\n",
    "    return pfits[np.argsort(pfits[:,0])[::-1],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1391,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_750 = r'folder_1'\n",
    "dax_fls_750 = glob.glob(folder_750+os.sep+'*.dax')\n",
    "folder_647 = r'fodler_2_colorswapped'\n",
    "dax_fls_647 = glob.glob(folder_647+os.sep+'*.dax')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zxys_750 = []\n",
    "zxys_647 = []\n",
    "for dax_fl1,dax_fl2 in tqdm(zip(dax_fls_750[1:],dax_fls_647[1:])):\n",
    "    #get image 1 and fit both image and beads 1\n",
    "    im1,im_beads1 = get_im(dax_fl1,icols = [0,2],num_cols=3)\n",
    "    #im1,im_beads1 = im1[4:-4],im_beads1[4:-4]\n",
    "    pfits1 = get_standard_fits(im1,th_stds = 10,sz_blur=10)\n",
    "    pfits_beads1 = get_standard_fits(im_beads1,th_stds = 6,sz_blur=10)\n",
    "    #get image 2 and fit both image and beads 2\n",
    "    im2,im_beads2 = get_im(dax_fl2,icols = [1,2],num_cols=3)\n",
    "    #im2,im_beads2 = im2[4:-4],im_beads2[4:-4]\n",
    "    pfits2 = get_standard_fits(im2,th_stds = 10,sz_blur=10)\n",
    "    pfits_beads2 = get_standard_fits(im_beads2,th_stds = 6,sz_blur=10)\n",
    "\n",
    "\n",
    "    tz,tx,ty = ft.fft3d_from2d(im_beads1,im_beads2)\n",
    "    pfits_beads2_ = pfits_beads2[:,1:4]+[tz,tx,ty]\n",
    "    pfits_beads1_ = pfits_beads1[:,1:4]\n",
    "    from scipy.spatial.distance import cdist\n",
    "    M = cdist(pfits_beads2_,pfits_beads1_)\n",
    "    iM = np.argmin(M,0)\n",
    "    jM = np.arange(len(iM))\n",
    "    keep = M[iM,jM]<5\n",
    "    tzxy = np.median(pfits_beads2[iM[keep],1:4]-pfits_beads1[jM[keep],1:4],axis=0)\n",
    "    pfits1_ = pfits1[:,1:4]\n",
    "    pfits2_ = pfits2[:,1:4]-tzxy\n",
    "    \n",
    "    M = cdist(pfits2_,pfits1_)\n",
    "    iM = np.argmin(M,0)\n",
    "    jM = np.arange(len(iM))\n",
    "    keep = M[iM,jM]<5\n",
    "    zxy1,zxy2 = pfits1_[jM[keep]],pfits2_[iM[keep]]\n",
    "    zxys_750.append(zxy1)\n",
    "    zxys_647.append(zxy2)\n",
    "    \n",
    "zxys_750 = np.array(zxys_750)\n",
    "zxys_647 = np.array(zxys_647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "#keep = (zxys_750[:,2]>1024-100)&(zxys_750[:,2]<1024+100)\n",
    "#plt.plot(zxys_750[keep,1],zxys_750[keep,0],'o')\n",
    "#plt.plot(zxys_647[keep,1],zxys_647[keep,0],'o')\n",
    "plt.plot(zxys_750[:,1],zxys_750[:,2],'o')\n",
    "plt.plot(zxys_647[:,1],zxys_647[:,2],'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zxy_647,zxy_750 = dic_chr['zxy_647_750']*[200/150.,1,1]\n",
    "dic_chr_['m_750_647'] = ft.calc_color_matrix(zxy_750,zxy_647+[0.5,0,0])\n",
    "zxy_561,zxy_750 = dic_chr['zxy_561_750']*[200/150.,1,1]\n",
    "dic_chr_['m_750_561'] = ft.calc_color_matrix(zxy_750,zxy_561+[0.75,0,0])\n",
    "fl = r'ChromaticAberation\\dic_chr_150nm.pkl'\n",
    "pickle.dump(dic_chr_,open(fl,'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
